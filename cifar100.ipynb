{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, Dropout, Input\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(X_test,y_test):\n",
    "    print('loading image...')\n",
    "    pos = 1\n",
    "    index = random.randint(0, X_test.shape[0]/2)\n",
    "    i = index\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "\n",
    "    for img in X_test[index:index+100]:\n",
    "        plt.subplot(10, 10, pos)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(CIFAR100_LABELS_LIST[y_test[i][0]])\n",
    "        pos += 1\n",
    "        i += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cifar():\n",
    "    (cifar_X_1, cifar_y_1), (cifar_X_2, cifar_y_2) = cifar100.load_data(label_mode='fine')\n",
    "    \n",
    "    cifar_X = np.r_[cifar_X_1, cifar_X_2]\n",
    "    cifar_y = np.r_[cifar_y_1, cifar_y_2]\n",
    "\n",
    "    cifar_X = cifar_X.astype('float32') / 255\n",
    "    cifar_y = np.eye(100)[cifar_y.astype('int32').flatten()]\n",
    "\n",
    "    #data split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cifar_X, cifar_y,test_size=10000,random_state=42)\n",
    "    \n",
    "    #call plot_image\n",
    "    plot_image(cifar_X_2, cifar_y_2)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFAR100_LABELS_LIST = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # loss\n",
    "# def plot_history_loss(fit):\n",
    "#     # Plot the loss in the history\n",
    "#     axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "#     axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "#     axL.set_title('model loss')\n",
    "#     axL.set_xlabel('epoch')\n",
    "#     axL.set_ylabel('loss')\n",
    "#     axL.legend(loc='upper right')\n",
    "\n",
    "# # acc\n",
    "# def plot_history_acc(fit):\n",
    "#     # Plot the loss in the history\n",
    "#     axR.plot(fit.history['acc'],label=\"loss for training\")\n",
    "#     axR.plot(fit.history['val_acc'],label=\"loss for validation\")\n",
    "#     axR.set_title('model accuracy')\n",
    "#     axR.set_xlabel('epoch')\n",
    "#     axR.set_ylabel('accuracy')\n",
    "#     axR.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(X_train, Y_train, X_test, batch_size, epochs, lr_rate):\n",
    "# def create_model(X_train, Y_train, X_test, batch_size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3, 3), padding='same',input_shape=X_train.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=lr_rate), metrics=['accuracy'])\n",
    "    \n",
    "#     model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model = Model(input=vgg16.input, output=top_model(vgg16.output))\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "batch_size = 128\n",
    "epochs = 150\n",
    "callbacks = []\n",
    "callbacks.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto'))\n",
    "\n",
    "print('loading data...')\n",
    "X_train, X_test, y_train, y_test = load_cifar()\n",
    "for i in range(2,5):\n",
    "    lr_rate = 10 ** -i\n",
    "    print('create model...')\n",
    "    model = create_model(X_train, y_train, X_test, batch_size, epochs,lr_rate)\n",
    "    # model = create_model(X_train, y_train, X_test, batch_size, epochs)\n",
    "\n",
    "    fit = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,callbacks=callbacks, validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "    print('lr_rate:', lr_rate)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('-' * 60)\n",
    "\n",
    "    #loss\n",
    "    \n",
    "    fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss[' + str(i) + ']' )\n",
    "#     axL.set_title('model loss' + batch_size + lr_rate)\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "    #acc\n",
    "    axR.plot(fit.history['acc'],label=\"loss for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"loss for validation\")\n",
    "    axR.set_title('model accuracy[' + str(i) + ']' )\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "#         fig.savefig('../image/cifar100.png')\n",
    "#         model.save(\"../model/model\" + str(i)+ \".h5\")\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr=1e-3\n",
    "Test loss: 1.85253411331\n",
    "Test accuracy: 0.5181\n",
    "43s\n",
    "18epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
